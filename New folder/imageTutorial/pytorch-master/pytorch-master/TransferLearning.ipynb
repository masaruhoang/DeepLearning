{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models,transforms,datasets\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import bcolz\n",
    "import time\n",
    "from utils import *\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.11+8aa1cef'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prep1 = transforms.Compose([\n",
    "            transforms.RandomSizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'dogsandcats/'\n",
    "\n",
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
    "         for x in ['train', 'val']}\n",
    "\n",
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=64,\n",
    "                                               shuffle=False, num_workers=6)\n",
    "                for x in ['train', 'val']}\n",
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "dset_classes = dsets['train'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying last layer and setting the gradient false to all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "model_vgg.classifier[6].out_features = 2\n",
    "for param in model_vgg.classifier[6].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg = model_vgg.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preconvfeat(dataset):\n",
    "    conv_features = []\n",
    "    labels_list = []\n",
    "    for data in dataset:\n",
    "        inputs,labels = data\n",
    "\n",
    "        inputs , labels = Variable(inputs.cuda()),Variable(labels.cuda())\n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.2 s, sys: 14.4 s, total: 1min 7s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_train,labels_train = preconvfeat(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.8 s, sys: 1.33 s, total: 6.13 s\n",
      "Wall time: 6.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_val,labels_val = preconvfeat(dset_loaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array('conv_feat_train.bc',conv_feat_train)\n",
    "save_array('labels_train.bc',labels_train)\n",
    "save_array('conv_feat_val.bc',conv_feat_val)\n",
    "save_array('labels_val.bc',labels_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat_train = load_array('conv_feat_train.bc')\n",
    "labels_train = load_array('labels_train.bc')\n",
    "conv_feat_val = load_array('conv_feat_val.bc')\n",
    "labels_val = load_array('labels_val.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 512, 7, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training fully connected module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen(conv_feat,labels,batch_size=64,shuffle=True):\n",
    "    labels = np.array(labels)\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(len(conv_feat))\n",
    "        conv_feat = conv_feat[index]\n",
    "        labels = labels[index]\n",
    "    for idx in range(0,len(conv_feat),batch_size):\n",
    "        yield(conv_feat[idx:idx+batch_size],labels[idx:idx+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model,size,conv_feat=None,labels=None,epochs=1,optimizer=None,train=True,shuffle=True):\n",
    "    for epoch in range(epochs):\n",
    "        batches = data_gen(conv_feat=conv_feat,labels=labels,shuffle=shuffle)\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs,classes in batches:\n",
    "            inputs , classes = Variable(torch.from_numpy(inputs).cuda()),Variable(torch.from_numpy(classes).cuda())\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,classes)           \n",
    "            if train:\n",
    "                if optimizer is None:\n",
    "                    raise ValueError('Pass optimizer for train mode')\n",
    "                optimizer = optimizer\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects / size\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch_loss, epoch_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016 Acc: 0.9570\n",
      "Loss: 0.0016 Acc: 0.9590\n",
      "Loss: 0.0015 Acc: 0.9597\n",
      "Loss: 0.0015 Acc: 0.9617\n",
      "Loss: 0.0015 Acc: 0.9598\n",
      "Loss: 0.0015 Acc: 0.9607\n",
      "Loss: 0.0014 Acc: 0.9621\n",
      "Loss: 0.0015 Acc: 0.9627\n",
      "Loss: 0.0014 Acc: 0.9619\n",
      "Loss: 0.0014 Acc: 0.9610\n",
      "CPU times: user 20.4 s, sys: 5.04 s, total: 25.5 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(train_model(model=model_vgg.classifier,size=dset_sizes['train'],conv_feat=conv_feat_train,labels=labels_train,\n",
    "            epochs=10,optimizer=optimizer,train=True,shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0015 Acc: 0.9665\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat=conv_feat_val,labels=labels_val,model=model_vgg.classifier\n",
    "            ,size=dset_sizes['val'],train=False,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training all the last Linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model_vgg.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(model_vgg.classifier.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0014 Acc: 0.9608\n",
      "Loss: 0.0012 Acc: 0.9678\n",
      "Loss: 0.0010 Acc: 0.9722\n",
      "Loss: 0.0009 Acc: 0.9764\n",
      "Loss: 0.0008 Acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat=conv_feat_train,labels=labels_train,model=model_vgg.classifier\n",
    "            ,size=dset_sizes['train'],epochs=5,optimizer=optimizer,train=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_lr_by(value=0.1,optimizer=None):\n",
    "    if optimizer is None:\n",
    "        raise ValueError('Pass in a valid optimizer')\n",
    "    optimizer = optimizer\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * 0.1\n",
    "        print('updated learning rate to {}'.format(param_group['lr']))\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated learning rate to 0.001\n"
     ]
    }
   ],
   "source": [
    "optimizer = update_lr_by(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006 Acc: 0.9836\n",
      "Loss: 0.0007 Acc: 0.9833\n",
      "Loss: 0.0006 Acc: 0.9853\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat=conv_feat_train,labels=labels_train,model=model_vgg.classifier\n",
    "            ,size=dset_sizes['train'],epochs=5,optimizer=optimizer,train=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg.classifier[5].p = 0.2\n",
    "model_vgg.classifier[2].p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004 Acc: 0.9920\n",
      "Loss: 0.0004 Acc: 0.9922\n",
      "Loss: 0.0004 Acc: 0.9936\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat=conv_feat_train,labels=labels_train,model=model_vgg.classifier\n",
    "            ,size=dset_sizes['train'],epochs=5,optimizer=optimizer,train=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add Batch Nomralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_vgg_bn = models.vgg16_bn()\n",
    "models_vgg_bn = models_vgg_bn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.SGD(models_vgg_bn.classifier.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0078 Acc: 0.8325\n",
      "Loss: 0.0033 Acc: 0.9153\n",
      "Loss: 0.0026 Acc: 0.9296\n",
      "Loss: 0.0024 Acc: 0.9351\n",
      "Loss: 0.0022 Acc: 0.9416\n",
      "Loss: 0.0021 Acc: 0.9430\n",
      "Loss: 0.0020 Acc: 0.9470\n",
      "Loss: 0.0019 Acc: 0.9504\n",
      "Loss: 0.0018 Acc: 0.9514\n",
      "Loss: 0.0018 Acc: 0.9523\n",
      "Loss: 0.0017 Acc: 0.9540\n",
      "Loss: 0.0017 Acc: 0.9563\n",
      "Loss: 0.0016 Acc: 0.9580\n",
      "Loss: 0.0015 Acc: 0.9595\n",
      "Loss: 0.0015 Acc: 0.9611\n",
      "Loss: 0.0015 Acc: 0.9607\n",
      "Loss: 0.0014 Acc: 0.9632\n",
      "Loss: 0.0014 Acc: 0.9634\n",
      "Loss: 0.0013 Acc: 0.9650\n",
      "Loss: 0.0013 Acc: 0.9647\n",
      "Loss: 0.0013 Acc: 0.9673\n",
      "Loss: 0.0013 Acc: 0.9677\n",
      "Loss: 0.0012 Acc: 0.9685\n",
      "Loss: 0.0012 Acc: 0.9675\n",
      "Loss: 0.0012 Acc: 0.9703\n",
      "Loss: 0.0011 Acc: 0.9704\n",
      "Loss: 0.0011 Acc: 0.9707\n",
      "Loss: 0.0011 Acc: 0.9717\n",
      "Loss: 0.0011 Acc: 0.9729\n",
      "Loss: 0.0010 Acc: 0.9731\n",
      "Loss: 0.0010 Acc: 0.9749\n",
      "Loss: 0.0010 Acc: 0.9733\n",
      "Loss: 0.0010 Acc: 0.9753\n",
      "Loss: 0.0009 Acc: 0.9776\n",
      "Loss: 0.0009 Acc: 0.9762\n",
      "Loss: 0.0009 Acc: 0.9783\n",
      "Loss: 0.0009 Acc: 0.9766\n",
      "Loss: 0.0009 Acc: 0.9776\n",
      "Loss: 0.0008 Acc: 0.9798\n",
      "Loss: 0.0008 Acc: 0.9799\n",
      "Loss: 0.0008 Acc: 0.9798\n",
      "Loss: 0.0008 Acc: 0.9802\n",
      "Loss: 0.0008 Acc: 0.9817\n",
      "Loss: 0.0007 Acc: 0.9809\n",
      "Loss: 0.0007 Acc: 0.9824\n",
      "Loss: 0.0007 Acc: 0.9831\n",
      "Loss: 0.0007 Acc: 0.9835\n",
      "Loss: 0.0006 Acc: 0.9851\n",
      "Loss: 0.0006 Acc: 0.9857\n",
      "Loss: 0.0006 Acc: 0.9847\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat=conv_feat_train,labels=labels_train,model=models_vgg_bn.classifier\n",
    "            ,size=dset_sizes['train'],epochs=50,optimizer=optimizer,train=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model(conv_feat=conv_feat_val,labels=labels_val,model=models_vgg_bn.classifier\n",
    "            ,size=dset_sizes['val'],train=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adjusting dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_vgg_bn.classifier[5].p = 0.3\n",
    "models_vgg_bn.classifier[2].p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated learning rate to 1e-05\n"
     ]
    }
   ],
   "source": [
    "optimizer = update_lr_by(value=0.1,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0014 Acc: 0.9638\n",
      "Loss: 0.0014 Acc: 0.9647\n",
      "Loss: 0.0014 Acc: 0.9641\n",
      "Loss: 0.0014 Acc: 0.9652\n",
      "Loss: 0.0014 Acc: 0.9647\n",
      "Loss: 0.0014 Acc: 0.9663\n",
      "Loss: 0.0014 Acc: 0.9651\n",
      "Loss: 0.0014 Acc: 0.9660\n",
      "Loss: 0.0014 Acc: 0.9653\n",
      "Loss: 0.0014 Acc: 0.9644\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat=conv_feat_train,labels=labels_train,model=models_vgg_bn.classifier\n",
    "            ,size=dset_sizes['train'],epochs=50,optimizer=optimizer,train=True,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0016 Acc: 0.9590\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_feat_val,labels_val,models_vgg_bn.classifier,dset_sizes['val'],train=False,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training a model without preconvolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)\n",
    "model_vgg = model_vgg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model_vgg.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg.classifier[6].out_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(model_vgg.classifier.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0035 Acc: 0.9739\n",
      "Loss: 0.0005 Acc: 0.9927\n",
      "Loss: 0.0004 Acc: 0.9933\n",
      "Loss: 0.0003 Acc: 0.9931\n",
      "Loss: 0.0004 Acc: 0.9936\n",
      "Loss: 0.0003 Acc: 0.9940\n",
      "Loss: 0.0003 Acc: 0.9938\n",
      "Loss: 0.0003 Acc: 0.9933\n",
      "Loss: 0.0003 Acc: 0.9936\n",
      "Loss: 0.0003 Acc: 0.9938\n",
      "CPU times: user 10min 6s, sys: 2min 10s, total: 12min 17s\n",
      "Wall time: 15min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train=True\n",
    "for epoch in range(10):\n",
    "        #batches = data_gen(conv_feat=conv_feat,labels=labels,shuffle=shuffle)\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs,classes in dset_loaders['train']:\n",
    "            inputs , classes = Variable(inputs.cuda()),Variable(classes.cuda())\n",
    "            #inputs = inputs.view(inputs.size(0), -1)\n",
    "            outputs = model_vgg(inputs)\n",
    "            loss = criterion(outputs,classes)           \n",
    "            if train:\n",
    "                if optimizer is None:\n",
    "                    raise ValueError('Pass optimizer for train mode')\n",
    "                optimizer = optimizer\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / dset_sizes['train']\n",
    "        epoch_acc = running_corrects / dset_sizes['train']\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003 Acc: 0.9935\n",
      "Loss: 0.0003 Acc: 0.9936\n",
      "Loss: 0.0003 Acc: 0.9940\n",
      "Loss: 0.0003 Acc: 0.9940\n",
      "Loss: 0.0003 Acc: 0.9934\n",
      "Loss: 0.0003 Acc: 0.9934\n",
      "Loss: 0.0003 Acc: 0.9932\n",
      "Loss: 0.0003 Acc: 0.9937\n",
      "Loss: 0.0003 Acc: 0.9933\n",
      "Loss: 0.0003 Acc: 0.9934\n",
      "CPU times: user 9min 32s, sys: 2min 11s, total: 11min 44s\n",
      "Wall time: 11min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train=True\n",
    "for epoch in range(10):\n",
    "        #batches = data_gen(conv_feat=conv_feat,labels=labels,shuffle=shuffle)\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs,classes in dset_loaders['train']:\n",
    "            inputs , classes = Variable(inputs.cuda()),Variable(classes.cuda())\n",
    "            #inputs = inputs.view(inputs.size(0), -1)\n",
    "            outputs = model_vgg(inputs)\n",
    "            loss = criterion(outputs,classes)           \n",
    "            if train:\n",
    "                if optimizer is None:\n",
    "                    raise ValueError('Pass optimizer for train mode')\n",
    "                optimizer = optimizer\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / dset_sizes['train']\n",
    "        epoch_acc = running_corrects / dset_sizes['train']\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
