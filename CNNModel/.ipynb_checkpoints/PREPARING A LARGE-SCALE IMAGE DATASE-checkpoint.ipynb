{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARING A LARGE-SCALE IMAGE DATASET WITH TENSORFLOW'S TFRECORD FILES\n",
    "\n",
    "\n",
    "#### Data Structure\n",
    "flowers\\\n",
    "    \n",
    "    flower_photos\\\n",
    "    \n",
    "        tulips\\\n",
    "            ....jpg\n",
    "            ....jpg\n",
    "            ....jpg\n",
    "        sunflowers\\\n",
    "            ....jpg\n",
    "        roses\\\n",
    "            ....jpg\n",
    "        dandelion\\\n",
    "            ....jpg\n",
    "        daisy\\\n",
    "            ....jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITING A TFRECORD FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n",
      ">> Converting image 2569/2569 shard 1\n",
      ">> Converting image 1101/1101 shard 1\n",
      "\n",
      "Finished converting the flower dataset!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from dataset_utils import _dataset_exists, _get_filenames_and_classes, write_label_file, _convert_dataset\n",
    "\n",
    "\n",
    "dataset_dir = \"flowers/\"\n",
    "validation_size = 0.3\n",
    "num_shards = 2\n",
    "random_seed = 0\n",
    "tfrecord_filename = 'flower'\n",
    "\n",
    "#=============CHECKS==============\n",
    "#Check if there is a tfrecord_filename entered\n",
    "if not tfrecord_filename:\n",
    "    raise ValueError('tfrecord_filename is empty. Please state a tfrecord_filename argument.')\n",
    "\n",
    "#Check if there is a dataset directory entered\n",
    "if not dataset_dir:\n",
    "    raise ValueError('dataset_dir is empty. Please state a dataset_dir argument.')\n",
    "\n",
    "#If the TFRecord files already exist in the directory, then exit without creating the files again\n",
    "if _dataset_exists(dataset_dir = dataset_dir, _NUM_SHARDS = num_shards, output_filename = tfrecord_filename):\n",
    "    print ('Dataset files already exist. Exiting without re-creating them.')\n",
    "#==========END OF CHECKS============\n",
    "\n",
    "#Get a list of photo_filenames like ['123.jpg', '456.jpg'...] and a list of sorted class names from parsing the subdirectories.\n",
    "photo_filenames, class_names = _get_filenames_and_classes(dataset_dir)\n",
    "\n",
    "print(len(photo_filenames))\n",
    "#Refer each of the class name to a specific integer number for predictions later\n",
    "class_names_to_ids = dict(zip(class_names, range(len(class_names))))\n",
    "\n",
    "#Find the number of validation examples we need\n",
    "num_validation = int(validation_size * len(photo_filenames))\n",
    "\n",
    "# Divide the training datasets into train and test:\n",
    "random.seed(random_seed)\n",
    "random.shuffle(photo_filenames)\n",
    "training_filenames = photo_filenames[num_validation:]\n",
    "validation_filenames = photo_filenames[:num_validation]\n",
    "\n",
    "# First, convert the training and validation sets.\n",
    "_convert_dataset('train', training_filenames, class_names_to_ids,\n",
    "                 dataset_dir = dataset_dir,\n",
    "                 tfrecord_filename = tfrecord_filename,\n",
    "                 _NUM_SHARDS = num_shards)\n",
    "_convert_dataset('validation', validation_filenames, class_names_to_ids,\n",
    "                 dataset_dir = dataset_dir,\n",
    "                 tfrecord_filename = tfrecord_filename,\n",
    "                 _NUM_SHARDS = num_shards)\n",
    "\n",
    "# Finally, write the labels file:\n",
    "labels_to_class_names = dict(zip(range(len(class_names)), class_names))\n",
    "write_label_file(labels_to_class_names, dataset_dir)\n",
    "\n",
    "print ( '\\nFinished converting the %s dataset!' % (tfrecord_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
